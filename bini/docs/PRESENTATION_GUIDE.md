# BINI ν”„λ΅μ νΈ λ°ν‘ κ°€μ΄λ“

> μ΅°μ›λ“¤μ—κ² μ„¤λ…ν•  λ• μ‚¬μ©ν•λ” κ°€μ΄λ“

---

## 1. ν”„λ΅μ νΈ ν• μ¤„ μ”μ•½

**"1Bμ§λ¦¬ μ‘μ€ λ¨λΈμ„ νΉν— μΉ¨ν•΄ νλ‹¨ μ „λ¬Έκ°€λ΅ λ§λ“¤μ—λ‹¤"**

- μ…λ ¥: μ‚¬μ©μ μ ν’ μ„¤λ… + νΉν— μ²­κµ¬ν•­
- μ¶λ ¥: μΉ¨ν•΄ λ¦¬μ¤ν¬ (λ†’μ/μ• λ§¤/λ‚®μ) + JSON ν•μ‹ λ¶„μ„ κ²°κ³Ό
- μ„±λ¥: **97.1% μ •ν™•λ„**

---

## 2. μ‚¬μ©ν• λ¨λΈ: Gemma 3 1B

### 2.1 Gemmaλ€?
- **κ°λ°μ‚¬**: Google DeepMind
- **κ³µκ°μΌ**: 2024λ…„
- **νΉμ§•**: μ¤ν”μ†μ¤ LLM (Large Language Model)
- **μ΄λ¦„ μ λ**: λΌν‹΄μ–΄λ΅ "λ³΄μ„(Gem)"

### 2.2 μ™ Gemma 1Bλ¥Ό μ„ νƒν–λ‚?

| λ¨λΈ | νλΌλ―Έν„° | GPU λ©”λ¨λ¦¬ | μ„ νƒ μ΄μ  |
|------|----------|------------|-----------|
| GPT-4 | ~1.7T | μλ°± GB | λ„λ¬΄ νΌ, API λΉ„μ© |
| Llama 70B | 70B | ~140GB | λ„λ¬΄ νΌ |
| **Gemma 1B** | **1B** | **~4GB** | β… κ°€λ³κ³ , λΉ λ¥΄κ³ , λ¬΄λ£ |

### 2.3 1Bκ°€ λ­μ•Ό?
- **1B = 1 Billion = 10μ–µ κ°μ νλΌλ―Έν„°**
- νλΌλ―Έν„° = λ¨λΈμ΄ ν•™μµν• "μ§€μ‹"μ„ μ €μ¥ν•λ” μ«μλ“¤
- λΉ„μ : λ‡μ μ‹λƒ…μ¤ μ—°κ²° κ°μμ™€ λΉ„μ·

```
GPT-4:     ~1,700,000,000,000 κ° (1.7μ΅°)
Gemma 1B:      1,000,000,000 κ° (10μ–µ)
                    β†‘
            μ°λ¦¬κ°€ μ“΄ λ¨λΈ (1700λ°° μ‘μ)
```

### 2.4 "-it"κ°€ λ­μ•Ό?
- `google/gemma-3-1b-it`μ—μ„ **it = Instruction Tuned**
- μ΄λ―Έ "μ§€μ‹λ¥Ό λ”°λ¥΄λ” λ²•"μ„ λ°°μ΄ λ¨λΈ
- μ°λ¦¬λ” μ—¬κΈ°μ— "νΉν— λ¶„μ„ν•λ” λ²•"μ„ μ¶”κ°€λ΅ κ°€λ¥΄μΉ¨

---

## 3. ν•™μµ λ°©λ²•: LoRA (λ΅λΌ)

### 3.1 Fine-tuningμ΄λ€?
```
μ‚¬μ „ν•™μµλ λ¨λΈ (μΌλ° μ§€μ‹)
        β†“
    Fine-tuning
        β†“
νΉν™”λ λ¨λΈ (νΉν— λ¶„μ„ μ „λ¬Έκ°€)
```

- μ΄λ―Έ ν•™μµλ λ¨λΈμ„ **νΉμ • μ‘μ—…μ— λ§κ² μ¶”κ°€ ν•™μµ**ν•λ” κ²ƒ
- λΉ„μ : μλ€ μ΅Έμ—…μƒ(μΌλ° μμ‚¬)μ„ ν”Όλ¶€κ³Ό μ „λ¬Έμλ΅ μλ ¨μ‹ν‚¤λ” κ²ƒ

### 3.2 μ™ LoRAλ¥Ό μΌλ‚?

**λ¬Έμ **: 10μ–µ κ° νλΌλ―Έν„°λ¥Ό μ „λ¶€ ν•™μµμ‹ν‚¤λ©΄?
- λ©”λ¨λ¦¬ λ¶€μ΅± (GPU ν„°μ§)
- μ‹κ°„ μ¤λ κ±Έλ¦Ό
- μ›λ³Έ λ¨λΈ μ†μƒ μ„ν—

**ν•΄κ²°**: LoRA (Low-Rank Adaptation)

### 3.3 LoRA μ›λ¦¬ (μ‰¬μ΄ μ„¤λ…)

```
[κΈ°μ΅΄ λ°©μ‹: Full Fine-tuning]
λ¨λΈ μ „μ²΄ 10μ–µ κ° νλΌλ―Έν„° μμ • β†’ GPU ν­λ° π’¥

[LoRA λ°©μ‹]
λ¨λΈμ€ κ·Έλ€λ΅ λ‘κ³  (Frozen)
μ‘μ€ "μ–΄λ‘ν„°"λ§ ν•™μµ β†’ GPU OK β…
```

**λΉ„μ λ΅ μ„¤λ…ν•λ©΄:**

```
Full Fine-tuning = μ§‘ μ „μ²΄ λ¦¬λ¨λΈλ§ (λΉ„μ, μ¤λ κ±Έλ¦Ό)
LoRA = κ°€κµ¬λ§ λ°”κΎΈκΈ° (μ €λ ΄, λΉ λ¦„)
```

### 3.4 LoRA μν•™μ  μ›λ¦¬ (κ°„λ‹¨ν)

μ›λ κ°€μ¤‘μΉ ν–‰λ ¬ Wλ¥Ό μ—…λ°μ΄νΈν•  λ•:
```
W_new = W_old + Ξ”W
```

LoRAλ” Ξ”Wλ¥Ό **μ €λ­ν¬ λ¶„ν•΄**:
```
Ξ”W = A Γ— B

μ—¬κΈ°μ„:
- W: 1024 Γ— 1024 = 1,048,576 κ° νλΌλ―Έν„°
- A: 1024 Γ— 16 = 16,384 κ°
- B: 16 Γ— 1024 = 16,384 κ°
- A Γ— B = 32,768 κ° (97% κ°μ†!)
```

### 3.5 μ°λ¦¬κ°€ μ‚¬μ©ν• LoRA μ„¤μ •

```yaml
r: 16              # λ­ν¬ (μ‘μ„μλ΅ κ°€λ²Όμ›€)
lora_alpha: 32     # μ¤μΌ€μΌλ§ ν©ν„°
lora_dropout: 0.05 # κ³Όμ ν•© λ°©μ§€
target_modules: all-linear  # μ–΄λ””μ— μ μ©ν• μ§€
```

**κ²°κ³Ό**:
- μ›λ³Έ λ¨λΈ: 1B (10μ–µ) νλΌλ―Έν„° β†’ κ±΄λ“λ¦¬μ§€ μ•μ
- LoRA μ–΄λ‘ν„°: ~50MBλ§ ν•™μµ β†’ μ΄κ²ƒλ§ μ €μ¥

---

## 4. ν•™μµ λ°μ΄ν„°: SFT (Supervised Fine-Tuning)

### 4.1 SFTλ€?
- **Supervised** = μ •λ‹µμ΄ μλ” (μ§€λ„ ν•™μµ)
- **Fine-Tuning** = μ¶”κ°€ ν•™μµ

### 4.2 λ°μ΄ν„° ν•μ‹

```
μ…λ ¥ (Prompt):
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚ [μ‹μ¤ν…]                              β”‚
β”‚ λ„λ” νΉν— μΉ¨ν•΄ λ¦¬μ¤ν¬λ¥Ό ν‰κ°€ν•λ” λ¨λΈμ΄λ‹¤  β”‚
β”‚                                       β”‚
β”‚ [μ‚¬μ©μ]                              β”‚
β”‚ μ ν’: tributyl acetylcitrate μ•°ν”      β”‚
β”‚ νΉν—: μ•„μ„Έν‹ΈνΈλ¦¬λ¶€ν‹Έμ¤νΈλ μ΄νΈ ν™”μ¥λ£...   β”‚
β”‚                                       β”‚
β”‚ μΉ¨ν•΄ λ¦¬μ¤ν¬λ¥Ό ν‰κ°€ν•λΌ                   β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
                β†“
μ¶λ ¥ (μ •λ‹µ):
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚ {                                    β”‚
β”‚   "risk_level": "λ†’μ",              β”‚
β”‚   "comparisons": [...],              β”‚
β”‚   "decision_reason": "..."           β”‚
β”‚ }                                    β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
```

### 4.3 μ°λ¦¬ λ°μ΄ν„°μ…‹

| ν•­λ© | λ‚΄μ© |
|------|------|
| μ΄ μƒν” μ | 35κ° |
| νΉν— | 1κ° (λ―Έλ°± ν™”μ¥λ£) |
| risk_level λ¶„ν¬ | λ†’μ 10, μ• λ§¤ 11, λ‚®μ 14 |

---

## 5. ν•™μµ κ³Όμ •

### 5.1 ν•™μµ μ„¤μ •

```yaml
epochs: 10          # μ „μ²΄ λ°μ΄ν„° 10λ² λ°λ³µ
batch_size: 1       # ν• λ²μ— 1κ°μ”©
learning_rate: 2e-4 # ν•™μµλ¥ 
```

### 5.2 ν•™μµ κ³΅μ„ 

```
Epoch 1:  Loss 2.42 β†’ μ •ν™•λ„ 57%  (μ•„μ§ λ¨λ¦„)
Epoch 3:  Loss 0.27 β†’ μ •ν™•λ„ 94%  (λΉ λ¥΄κ² ν•™μµ)
Epoch 5:  Loss 0.06 β†’ μ •ν™•λ„ 99%  (κ±°μ λ‹¤ λ°°μ›€)
Epoch 10: Loss 0.03 β†’ μ •ν™•λ„ 99%  (μ™„λ£!)
```

### 5.3 ν•™μµ μ‹κ°„
- **λ‹¨ 2λ¶„ 14μ΄** (GPU: RTX 2000 Ada 16GB)

---

## 6. ν‰κ°€ κ²°κ³Ό

### 6.1 μµμΆ… μ„±λ¥

| λ©”νΈλ¦­ | κ²°κ³Ό |
|--------|------|
| JSON μ¶λ ¥ μ •ν™•λ„ | **100%** (35/35) |
| risk_level μ •ν™•λ„ | **97.1%** (34/35) |
| match μ •ν™•λ„ | **98.6%** (69/70) |

### 6.2 νΌλ™ ν–‰λ ¬ (Confusion Matrix)

```
μ‹¤μ  β†’      λ†’μ    μ• λ§¤    λ‚®μ
μμΈ΅ β†“
λ†’μ         8       0       0    β† μ™„λ²½
μ• λ§¤         0      12       0    β† μ™„λ²½
λ‚®μ         1       0      14    β† 1κ° μ‹¤μ
```

### 6.3 μ μΌν• μ¤λ¥

```
μ…λ ¥: "TBC μ„±λ¶„μ΄ λ“¤μ–΄κ°„ λ―Έλ°± ν¬λ¦Ό"
μμΈ΅: λ‚®μ (ν‹€λ¦Ό)
μ •λ‹µ: λ†’μ

μ›μΈ: TBC = tributyl acetylcitrateμ μ•½μ–΄
      β†’ λ¨λΈμ΄ μ•½μ–΄λ¥Ό λ» μ•μ•„λ΄„
ν•΄κ²°: μ•½μ–΄ λ°μ΄ν„° μ¶”κ°€ν•λ©΄ λ¨
```

---

## 7. ν•µμ‹¬ μ‹¤ν—: ν•™μµ vs λΉ„ν•™μµ

### 7.1 λΉ„κµ λ€μƒ
- **Fine-tuned 1B**: μ°λ¦¬κ°€ ν•™μµμ‹ν‚¨ λ¨λΈ
- **Base 4B**: ν•™μµ μ• ν• 4λ°° ν° λ¨λΈ

### 7.2 κ²°κ³Ό

| ν•­λ© | 1B (ν•™μµν•¨) | 4B (ν•™μµ μ•ν•¨) |
|------|-------------|----------------|
| νλΌλ―Έν„° | 10μ–µ | 40μ–µ |
| JSON μ¶λ ¥ | **100%** | 0% |
| μ •ν™•λ„ | **97.1%** | 0% |

### 7.3 κ²°λ΅ 

```
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚  μ‘μ€ λ¨λΈ + Fine-tuning > ν° λ¨λΈ + μ•„λ¬΄κ²ƒλ„   β”‚
β”‚                                              β”‚
β”‚  1B + LoRA (97%) >>> 4B Base (0%)           β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
```

**ν•µμ‹¬ μΈμ‚¬μ΄νΈ**:
- λ¨λΈ ν¬κΈ°λ³΄λ‹¤ **λ„λ©”μΈ νΉν™” ν•™μµ**μ΄ μ¤‘μ”
- ν° λ¨λΈλ„ νΉμ • ν•μ‹(JSON) μ¶λ ¥ λ»ν•¨
- μ‘μ€ λ¨λΈλ„ ν•™μµν•λ©΄ μ „λ¬Έκ°€ λ¨

---

## 8. κΈ°μ  μ¤νƒ μ •λ¦¬

| κµ¬λ¶„ | κΈ°μ  | μ©λ„ |
|------|------|------|
| Base Model | Gemma 3 1B | μ‚¬μ „ν•™μµλ LLM |
| Fine-tuning | LoRA | ν¨μ¨μ  νλΌλ―Έν„° ν•™μµ |
| ν•™μµ λ°©μ‹ | SFT | μ§€λ„ ν•™μµ |
| λΌμ΄λΈλ¬λ¦¬ | HuggingFace Transformers | λ¨λΈ λ΅λ“ |
| λΌμ΄λΈλ¬λ¦¬ | PEFT | LoRA μ μ© |
| λΌμ΄λΈλ¬λ¦¬ | TRL | SFT ν•™μµ |
| GPU | RTX 2000 Ada 16GB | ν•™μµ ν™κ²½ |

---

## 9. νμΌ κµ¬μ΅° μ„¤λ…

```
bini/
β”β”€β”€ data/
β”‚   β”β”€β”€ raw/seeds/seed_cases.json   β† μ…λ ¥ λ°μ΄ν„° 35κ°
β”‚   β”β”€β”€ processed/train.jsonl       β† μ •λ‹µ λΌλ²¨
β”‚   β””β”€β”€ processed/sft_train.jsonl   β† ν•™μµμ© λ°μ΄ν„°
β”‚
β”β”€β”€ training/
β”‚   β”β”€β”€ train.py          β† ν•™μµ μ‹¤ν–‰ μ½”λ“
β”‚   β”β”€β”€ evaluate.py       β† ν‰κ°€ μ½”λ“
β”‚   β”β”€β”€ inference.py      β† μ¶”λ΅  ν…μ¤νΈ
β”‚   β”β”€β”€ compare_models.py β† λ¨λΈ λΉ„κµ
β”‚   β””β”€β”€ lora_config.yaml  β† ν•™μµ μ„¤μ •
β”‚
β”β”€β”€ outputs/
β”‚   β””β”€β”€ gemma3-1b-it-lora/
β”‚       β”β”€β”€ adapter_model.safetensors β† ν•™μµλ LoRA (52MB)
β”‚       β””β”€β”€ tokenizer.json            β† ν† ν¬λ‚μ΄μ €
β”‚
β””β”€β”€ docs/
    β””β”€β”€ TRAINING_REPORT.md  β† μƒμ„Έ λ¦¬ν¬νΈ
```

---

## 10. Q&A μμƒ μ§λ¬Έ

### Q1: μ™ GPT-4 μ• μ“°κ³  μ‘μ€ λ¨λΈ μΌμ–΄μ”?
> λΉ„μ©, μ†λ„, ν”„λΌμ΄λ²„μ‹ λ•λ¬Έμ…λ‹λ‹¤.
> - GPT-4 API: νΈμ¶λ‹Ή λΉ„μ© λ°μƒ
> - λ΅μ»¬ λ¨λΈ: λ¬΄λ£, λΉ λ¦„, λ°μ΄ν„° μ μ¶ μ—†μ
> - νΉμ • μ‘μ—…μ—λ” μ‘μ€ λ¨λΈλ΅ μ¶©λ¶„

### Q2: LoRA λ§κ³  λ‹¤λ¥Έ λ°©λ²•μ€?
> - **Full Fine-tuning**: μ „μ²΄ ν•™μµ (λ©”λ¨λ¦¬ λ§μ΄ ν•„μ”)
> - **QLoRA**: LoRA + μ–‘μν™” (λ” κ°€λ²Όμ›€)
> - **Prefix Tuning**: ν”„λ΅¬ν”„νΈλ§ ν•™μµ
> - LoRAκ°€ κ°€μ¥ λ„λ¦¬ μ“°μ΄κ³  κ· ν• μΆ‹μ

### Q3: 35κ° λ°μ΄ν„°λ΅ μ¶©λ¶„ν•΄μ”?
> - ν„μ¬ 1κ° νΉν—μ— λ€ν•΄μ„λ” 97% λ‹¬μ„±
> - μΌλ°ν™”λ¥Ό μ„ν•΄μ„λ” λ” λ§μ€ νΉν— ν•„μ”
> - λ‹¤μ λ‹¨κ³„μ—μ„ λ°μ΄ν„° ν™•μ¥ μμ •

### Q4: μ‹¤μ  μ„λΉ„μ¤μ— μ“Έ μ μμ–΄μ”?
> - ν„μ¬: PoC (κ°λ… μ¦λ…) λ‹¨κ³„
> - ν•„μ”ν• κ²ƒ:
>   - λ” λ§μ€ ν•™μµ λ°μ΄ν„°
>   - λ‹¤μ–‘ν• μ‚°μ—… λ¶„μ•Ό νΉν—
>   - API μ„λ²„ κµ¬μ¶•
>   - λ²•λ¥  μ „λ¬Έκ°€ κ²€μ¦

### Q5: 4B, 8B λ¨λΈλ„ ν•™μµμ‹ν‚¬ κ±°μμ”?
> - λ„¤, λ΅λ“λ§µμ— μμ
> - 1B β†’ 4B β†’ 8B μμ„λ΅ μ§„ν–‰
> - λ¨λΈ ν¬κΈ°λ³„ μ„±λ¥ λΉ„κµ μμ •

---

## 11. λ°ν‘ μ¤ν¬λ¦½νΈ μμ‹

> "μ €ν¬ ν€μ€ νΉν— μΉ¨ν•΄ λ¦¬μ¤ν¬λ¥Ό μλ™μΌλ΅ νλ‹¨ν•λ” AIλ¥Ό λ§λ“¤μ—μµλ‹λ‹¤.
>
> κµ¬κΈ€μ Gemma 1B λ¨λΈμ„ λ² μ΄μ¤λ΅, LoRAλΌλ” ν¨μ¨μ μΈ λ°©λ²•μΌλ΅ ν•™μµμ‹μΌ°μµλ‹λ‹¤.
> LoRAλ” λ¨λΈ μ „μ²΄λ¥Ό μμ •ν•μ§€ μ•κ³  μ‘μ€ μ–΄λ‘ν„°λ§ ν•™μµν•λ” λ°©μ‹μ΄λΌ
> GPU λ©”λ¨λ¦¬λ„ μ κ² μ“°κ³  λΉ λ¦…λ‹λ‹¤.
>
> 35κ°μ ν•™μµ λ°μ΄ν„°λ΅ 2λ¶„ λ§μ— ν•™μµμ„ μ™„λ£ν–κ³ ,
> 97.1%μ μ •ν™•λ„λ¥Ό λ‹¬μ„±ν–μµλ‹λ‹¤.
>
> νΉν ν¥λ―Έλ΅μ΄ μ μ€, ν•™μµν•μ§€ μ•μ€ 4B λ¨λΈ(4λ°° ν° λ¨λΈ)κ³Ό λΉ„κµν–μ„ λ•
> μ €ν¬κ°€ ν•™μµμ‹ν‚¨ 1B λ¨λΈμ΄ μ••λ„μ μΌλ΅ μΆ‹μ•μµλ‹λ‹¤.
> 4B λ¨λΈμ€ JSON ν•μ‹ μ¶λ ¥λ„ λ»ν–κ±°λ“ μ”.
>
> μ΄κ²ƒμ€ λ¨λΈ ν¬κΈ°λ³΄λ‹¤ λ„λ©”μΈ νΉν™” ν•™μµμ΄ λ” μ¤‘μ”ν•λ‹¤λ” κ²ƒμ„ λ³΄μ—¬μ¤λ‹λ‹¤."

---

## 12. μ©μ–΄ μ‚¬μ „

| μ©μ–΄ | μ„¤λ… |
|------|------|
| **LLM** | Large Language Model, λ€κ·λ¨ μ–Έμ–΄ λ¨λΈ |
| **νλΌλ―Έν„°** | λ¨λΈμ΄ ν•™μµν• μ«μλ“¤ (κ°€μ¤‘μΉ) |
| **Fine-tuning** | μ‚¬μ „ν•™μµ λ¨λΈμ„ νΉμ • μ‘μ—…μ— λ§κ² μ¶”κ°€ ν•™μµ |
| **LoRA** | Low-Rank Adaptation, ν¨μ¨μ  fine-tuning λ°©λ²• |
| **SFT** | Supervised Fine-Tuning, μ •λ‹µμ΄ μλ” ν•™μµ |
| **Epoch** | μ „μ²΄ λ°μ΄ν„°λ¥Ό ν• λ² ν•™μµν•λ” λ‹¨μ„ |
| **Loss** | λ¨λΈ μμΈ΅κ³Ό μ •λ‹µμ μ°¨μ΄ (λ‚®μ„μλ΅ μΆ‹μ) |
| **Inference** | ν•™μµλ λ¨λΈλ΅ μμΈ΅ν•λ” κ²ƒ |
| **ν† ν¬λ‚μ΄μ €** | ν…μ¤νΈλ¥Ό μ«μλ΅ λ³€ν™ν•λ” λ„κµ¬ |

---

*μ΄ κ°€μ΄λ“λ¥Ό μ°Έκ³ ν•΄μ„ λ°ν‘ν•μ‹λ©΄ λ©λ‹λ‹¤!*
